{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Ww0KYL3CbawR",
    "outputId": "26cb4049-7d83-4234-96ff-ed0c778d8167"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0eTZqa1BbwKr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.utils import to_categorical\n",
    "import re\n",
    "import spacy\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.applications.resnet_v2 import ResNet152V2\n",
    "from keras.utils import plot_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Concatenate, Input, Flatten, Embedding, CuDNNLSTM, Bidirectional, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AC-v4eHLhkEB"
   },
   "outputs": [],
   "source": [
    "#load csv file\n",
    "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data_7000_new.csv\", names=['image_name', 'Image_URL', 'OCR_extracted_text', 'Corrected_text', 'Humour', 'Sarcasm', 'Offense', 'Motivation', 'Overall_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SwIvOXJJhtJn"
   },
   "outputs": [],
   "source": [
    "#clean data by removing rows with junk values\n",
    "df = df.drop(df[(df.Overall_sentiment != 'very_positive') & (df.Overall_sentiment != 'positive') & (df.Overall_sentiment != 'neutral') & (df.Overall_sentiment != 'negative') & (df.Overall_sentiment != 'very_negative')].index)\n",
    "df = df.drop(df[(df.Motivation != 'motivational') & (df.Motivation != 'not_motivational')].index)\n",
    "df = df.drop(df[(df.Offense != 'not_offensive') & (df.Offense != 'slight') & (df.Offense != 'very_offensive') & (df.Offense != 'hateful_offensive')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nAJ8R0qQh8Ir",
    "outputId": "00f7c62c-194e-4bdb-b5de-3b5c1e02b004"
   },
   "outputs": [],
   "source": [
    "#store all images in list after resizing them\n",
    "X_train_pics = []\n",
    "pic_ind = 0\n",
    "error_pics = set()\n",
    "for img in df['image_name']:\n",
    "    try:\n",
    "      im = cv2.imread(\"/content/drive/My Drive/data_7000/\" + str(img))\n",
    "      resized = cv2.resize(im, (256, 256), interpolation = cv2.INTER_AREA)\n",
    "      X_train_pics.append(resized)\n",
    "      print(\"Loaded pic no. \" + str(pic_ind))\n",
    "    except:\n",
    "      print(\"Error loading pic no. \" + str(pic_ind))\n",
    "      error_pics.add(pic_ind)\n",
    "    pic_ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyaI_7V7iLBE"
   },
   "outputs": [],
   "source": [
    "#delete entries of pics that couldn't be loaded\n",
    "df = df.drop([df.index[x] for x in error_pics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NMnoO1Fw1xR"
   },
   "outputs": [],
   "source": [
    "#perform text preprocessing\n",
    "X_train_text = df['Corrected_text'].apply(str).apply(lambda x: re.sub(r'[\\S]+\\.(net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil)[\\S]*\\s?','',x))\n",
    "punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
    "X_train_text = X_train_text.apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
    "X_train_text = X_train_text.str.lower()\n",
    "X_train_text = X_train_text.str.replace(\"[0-9]\", \" \")\n",
    "X_train_text = X_train_text.apply(lambda x:' '.join(x.split()))\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts):\n",
    "    output = []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output\n",
    "X_train_text = lemmatization(X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPOdpqkNxFWe"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "X_train_text = tokenizer.texts_to_sequences(X_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xs0cdvqI6SBS"
   },
   "outputs": [],
   "source": [
    "tokenizer_file = open(\"tokenizer\",'wb')\n",
    "pickle.dump(tokenizer,tokenizer_file)\n",
    "tokenizer_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xtx0aWXcxXao"
   },
   "outputs": [],
   "source": [
    "#169 is the length of the longest sequence\n",
    "X_train_text = pad_sequences(X_train_text, maxlen=169, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "XTfGXcZkxZGj",
    "outputId": "60d7b1f2-a293-4420-826d-8d9815f58770"
   },
   "outputs": [],
   "source": [
    "#import pretrained ResNet\n",
    "resnet_base = ResNet152V2(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
    "resnet_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJGbEKjk0kLJ"
   },
   "outputs": [],
   "source": [
    "#normalize images\n",
    "X_train_pics = np.array(X_train_pics)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "t2ThdlOFAXWj",
    "outputId": "7b093df0-c79b-44a5-c5d1-fd49f3ea2a8a"
   },
   "outputs": [],
   "source": [
    "#download Glove vectors\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip /content/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-adRmKh-DZbZ",
    "outputId": "92090920-e516-46f7-fdbf-1abe2d80123c"
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(\"/content/glove.6B.200d.txt\")\n",
    "for line in f:\n",
    "  values = line.split()\n",
    "  word = values[0]\n",
    "  coefs = np.asarray(values[1:], dtype='float32')\n",
    "  embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print(\"Found %s word vectors.\" %len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DI8FJQgCDn-u"
   },
   "outputs": [],
   "source": [
    "#generate embedding matrix for all tasks\n",
    "vocab_size = 5000\n",
    "word_index = tokenizer.word_index\n",
    "embedding_dim = 200\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "  if i<vocab_size:\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rschxSvjx6JT"
   },
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "r2bZ_x3GxvPn",
    "outputId": "288b4334-35b3-4dcb-b563-07bc9231aaf2"
   },
   "outputs": [],
   "source": [
    "input1_task1 = Input(shape=(256, 256, 3))\n",
    "input2_task1 = Input(shape=(169,))\n",
    "\n",
    "base_output_task1 = resnet_base(input1_task1)\n",
    "out1_task1 = Flatten()(base_output_task1)\n",
    "out1_task1 = Dense(128, activation='relu')(out1_task1)\n",
    "\n",
    "out2_task1 = Embedding(input_dim=5000, output_dim=200, input_length=169)(input2_task1)\n",
    "out2_task1 = Bidirectional(CuDNNLSTM(200, return_sequences=True))(out2_task1)\n",
    "out2_task1 = Bidirectional(CuDNNLSTM(64))(out2_task1)\n",
    "\n",
    "merged_task1 = Concatenate(axis=1)([out1_task1, out2_task1])\n",
    "merged_task1 = Dropout(0.5)(merged_task1)\n",
    "merged_task1 = Dense(128, activation='relu')(merged_task1)\n",
    "merged_task1 = Dropout(0.5)(merged_task1)\n",
    "merged_task1 = Dense(64, activation='relu')(merged_task1)\n",
    "merged_task1 = Dropout(0.5)(merged_task1)\n",
    "\n",
    "out_task1 = Dense(1, activation='sigmoid')(merged_task1)\n",
    "\n",
    "model_task1 = Model(inputs=[input1_task1,input2_task1], output=out_task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZ1MSAX2EXQ2"
   },
   "outputs": [],
   "source": [
    "model_task1.layers[3].set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwtVA7a6z4yO"
   },
   "outputs": [],
   "source": [
    "y_train_task1 = (df['Motivation'] == 'motivational')+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZAHrF4L0r9D"
   },
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\"balanced\", np.unique(y_train_task1), y_train_task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "e1VHXlavWUQf",
    "outputId": "386a5a44-03c3-402b-893f-b69c999a68e8"
   },
   "outputs": [],
   "source": [
    "#define function for F1 score\n",
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "model_task1.compile(loss='binary_crossentropy',\n",
    "          optimizer= \"adam\",\n",
    "          metrics=[f1, 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ItpSj3xmWgNH",
    "outputId": "468a92f0-e8a2-49bb-f9cd-8f03ddbd4b1c"
   },
   "outputs": [],
   "source": [
    "history_task1 = model_task1.fit([X_train_pics, X_train_text], y_train_task1, epochs=50, batch_size=256, validation_split=0.2, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "MUESIarOWoiL",
    "outputId": "9b367cae-e12f-4e33-8005-b24f6133e4d7"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_task1.history['f1'])\n",
    "plt.plot(history_task1.history['val_f1'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.legend((\"Train\", \"Val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "38Bl62swrfoq",
    "outputId": "eb4d06a4-65f9-41f5-fe8c-897ad496c053"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_task1.history['acc'])\n",
    "plt.plot(history_task1.history['val_acc'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend((\"Train\", \"Val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkKjw40deD06"
   },
   "outputs": [],
   "source": [
    "model_task1.save('Task1_50_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gh5cge-OfnqZ"
   },
   "source": [
    "# **TASK 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "tQ8K3GSefhGR",
    "outputId": "49854987-473d-4174-d07c-983fca21d902"
   },
   "outputs": [],
   "source": [
    "input1_task2 = Input(shape=(256, 256, 3))\n",
    "input2_task2 = Input(shape=(169,))\n",
    "\n",
    "base_output_task2 = resnet_base(input1_task2)\n",
    "out1_task2 = Flatten()(base_output_task2)\n",
    "out1_task2 = Dense(128, activation='relu')(out1_task2)\n",
    "\n",
    "out2_task2 = Embedding(input_dim=5000, output_dim=200, input_length=169)(input2_task2)\n",
    "out2_task2 = Bidirectional(CuDNNLSTM(200, return_sequences=True))(out2_task2)\n",
    "out2_task2 = Bidirectional(CuDNNLSTM(64))(out2_task2)\n",
    "\n",
    "merged_task2 = Concatenate(axis=1)([out1_task2, out2_task2])\n",
    "merged_task2 = Dropout(0.5)(merged_task2)\n",
    "merged_task2 = Dense(128, activation='relu')(merged_task2)\n",
    "merged_task2 = Dropout(0.5)(merged_task2)\n",
    "merged_task2 = Dense(64, activation='relu')(merged_task2)\n",
    "merged_task2 = Dropout(0.5)(merged_task2)\n",
    "\n",
    "out_task2 = Dense(5, activation='softmax')(merged_task2)\n",
    "\n",
    "model_task2 = Model(inputs=[input1_task2,input2_task2], output=out_task2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pSzZp0hgQj2"
   },
   "outputs": [],
   "source": [
    "y_train_task2 = df['Overall_sentiment'].replace(to_replace =[\"very_negative\", \"negative\", \"neutral\", \"positive\", \"very_positive\"],  \n",
    "                            value =[0, 1, 2, 3, 4]) \n",
    "y_train_task2_cat = to_categorical(y_train_task2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oXxjmJmkii_i"
   },
   "outputs": [],
   "source": [
    "model_task2.layers[3].set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "krelpbf7hubi"
   },
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\"balanced\", np.unique(y_train_task2), y_train_task2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vbum4LAriEDA"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "model_task2.compile(loss='binary_crossentropy',\n",
    "          optimizer= \"adam\",\n",
    "          metrics=[f1, 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Z8gzDfCcjDos",
    "outputId": "6c081328-b090-4ec4-8812-c35b816892b7"
   },
   "outputs": [],
   "source": [
    "history_task2 = model_task2.fit([X_train_pics, X_train_text], y_train_task2_cat, epochs=50, batch_size=256, validation_split=0.2, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "mpsUL933jPow",
    "outputId": "9334ea7f-3984-473a-d404-d8b215f563f2"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_task2.history['f1'])\n",
    "plt.plot(history_task2.history['val_f1'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.legend((\"Train\", \"Val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "3umtRb0mrbhw",
    "outputId": "9adba519-4400-45ec-9f9c-1d475588cc82"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_task2.history['acc'])\n",
    "plt.plot(history_task2.history['val_acc'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend((\"Train\", \"Val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9YFULOZPsRVT"
   },
   "outputs": [],
   "source": [
    "model_task2.save('Task2_50_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5KTVhf6sfPo"
   },
   "source": [
    "# **TASK 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "gBU6jcpDsabG",
    "outputId": "d56ba521-cd8b-44e7-8da8-9529bcb07ba5"
   },
   "outputs": [],
   "source": [
    "input1_task3 = Input(shape=(256, 256, 3))\n",
    "input2_task3 = Input(shape=(169,))\n",
    "\n",
    "base_output_task3 = resnet_base(input1_task3)\n",
    "out1_task3 = Flatten()(base_output_task3)\n",
    "out1_task3 = Dense(128, activation='relu')(out1_task3)\n",
    "\n",
    "out2_task3 = Embedding(input_dim=5000, output_dim=200, input_length=169)(input2_task3)\n",
    "out2_task3 = Bidirectional(CuDNNLSTM(200, return_sequences=True))(out2_task3)\n",
    "out2_task3 = Bidirectional(CuDNNLSTM(64))(out2_task3)\n",
    "\n",
    "merged_task3 = Concatenate(axis=1)([out1_task3, out2_task3])\n",
    "merged_task3 = Dropout(0.5)(merged_task3)\n",
    "merged_task3 = Dense(128, activation='relu')(merged_task3)\n",
    "merged_task3 = Dropout(0.5)(merged_task3)\n",
    "merged_task3 = Dense(64, activation='relu')(merged_task3)\n",
    "merged_task3 = Dropout(0.5)(merged_task3)\n",
    "\n",
    "out_task3 = Dense(1)(merged_task3)\n",
    "\n",
    "model_task3 = Model(inputs=[input1_task3,input2_task3], output=out_task3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "DEbtutiTuO0l",
    "outputId": "fa0654d9-d8e7-4ee0-93e6-217b45886cb4"
   },
   "outputs": [],
   "source": [
    "df['Offense'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVPLQiHd0_VS"
   },
   "outputs": [],
   "source": [
    "model_task3.layers[3].set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hk2ypUODtGQI"
   },
   "outputs": [],
   "source": [
    "y_train_task3 = df['Offense'].replace(to_replace =[\"not_offensive\", \"slight\", \"very_offensive\", \"hateful_offensive\"],  \n",
    "                            value =[0, 1, 2, 3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qRXShR6Au37w"
   },
   "outputs": [],
   "source": [
    "model_task3.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "ZEKgbuDevSks",
    "outputId": "4043268f-ca38-4bee-aa3f-5c916da9585a"
   },
   "outputs": [],
   "source": [
    "history_task3 = model_task3.fit([X_train_pics, X_train_text], y_train_task3, epochs=10, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "aSL6VbBBvf4W",
    "outputId": "545c1d1d-b5b1-499b-fa7d-1942347b2c52"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_task3.history['mean_absolute_error'])\n",
    "plt.plot(history_task3.history['val_mean_absolute_error'])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.legend((\"Train\", \"Val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oa2y3dHw0Gw7"
   },
   "outputs": [],
   "source": [
    "model_task3.save('Task3_15_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mh7vmhAc4BNQ"
   },
   "outputs": [],
   "source": [
    "!cp /content/Task2_50_epochs.h5 /content/drive/My\\ Drive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2pjpqIt4IWb"
   },
   "outputs": [],
   "source": [
    "!cp /content/Task3_15_epochs.h5 /content/drive/My\\ Drive/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Copy of NNFL_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
